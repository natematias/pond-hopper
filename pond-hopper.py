import re
import sys
import os
import requests
import datetime
from bs4 import BeautifulSoup
from feedgen.feed import FeedGenerator
import dateutil.parser
from pytz import timezone
import pytz
import flask
from flask import Flask
app = Flask(__name__)


class Article:
  def __init__(self, section, author=None):

    #extract information from the page
    title_link = section.findAll(attrs={"class":"river-headline"})[0].findAll("a")[0]
    self.title = title_link.get_text()
    self.url = title_link['href']
    eastern = timezone('US/Eastern')
    self.date = eastern.localize(dateutil.parser.parse(section.findAll(attrs={"class":"river-date"})[0].get_text()))
    self.subtitle = section.findAll(attrs={"class":"river-dek"})[0].get_text()
    self.bylines = []
    if author is None:
      for auth in section.findAll(attrs={"class":"author"}):
        self.bylines.append({"name": auth.get_text(), "url": auth['href']})
    else:
      self.bylines.append({"name":author})

    #TODO: download the first paragraph from the article

    #TODO: download social media metrics for the article

  def append_feedgen(self, fe):
 #   if (fg.id() is not None):
 #     fg.add_entry()
    fe.title(self.title)
    for byline in self.bylines:
      fe.author({"name":byline["name"]})
    fe.link(href=self.url)
    fe.id(self.url)
    fe.updated(self.date)
 #   fe.pubdate(self.date)
 #   fe.subtitle(self.subtitle)
    fe.description(self.subtitle)


# get a feed for a  byline
@app.route("/byline/<byline>")
def byline(byline):
  url = "http://www.theatlantic.com/" + byline.replace("/","") + "/"
  return get_url(url)


# get a feed for a section
@app.route("/section/<sectiona>/<sectionb>/<sectionc>/")
def section(sectiona,sectionb,sectionc):
  url = "http://www.theatlantic.com/{0}/{1}/{2}".format(sectiona,sectionb,sectionc)
  return get_url(url)

def get_url(url):
  res = requests.get(url)
  soup = BeautifulSoup(res.text)
#load the articles into classes
  articles = []

  author_tag = soup.findAll("h1", attrs={"class":"author"})
  author = None
  if len(author_tag)>0:
    author = ' '.join(author_tag[0].get_text().split())

  for article in soup.findAll(attrs={"class":"river-content"}):
    articles.append(Article(article, author=author))

#set up the feed, with basic metadata
  fg = FeedGenerator()
  fg.link(href=url)
  if(author is None):
    fg.author({"name":articles[0].bylines[0]})
  title_tag = soup.findAll(attrs={"class":"display-category"})

#set the title if there's not a category -- e.g. it's a person's page
  if(len(title_tag)>0):
    title = ' '.join(title_tag[0].get_text().split())
  else:
    title = "Atlantic posts by {0}".format(author)
  fg.title(title)

#set the description
  description = soup.findAll(attrs={"class":"bio"})
  if len(description)>0:
    fg.description(' '.join(description[0].get_text().split()))
  else:
    fg.description("RSS Feed for {0}, generated by Pond Hopper 0.1".format(title))

#add each article to the feed
  for article in articles:
    article.append_feedgen(fg.add_entry())

  return flask.Response(fg.rss_str(pretty=True), mimetype='application/rss+xml')

if __name__ == "__main__":
  app.debug = True
  app.run(host='0.0.0.0',port=5050)
